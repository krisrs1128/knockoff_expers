\documentclass{article}
\usepackage{natbib}
\usepackage{graphicx}
\input{preamble.tex}

\title{Notes on Knockoffs for the Microbiome}
\author{Kris Sankaran}

\begin{document}
\maketitle

There is a tension between modeling and inference in microbiome data analysis.
On the one hand, it has become possible to detect and model complex
relationships between patterns of species abundance and medical characteristics
of interest. However, formal descriptions of the uncertainty associated with
model estimates remains out of reach for all but the simplest -- say,
generalized linear or PERMANOVA -- models, and typically, to
do inference in microbiome studies, researchers fall back to some type of
marginal testing with False Discovery Rate (FDR) control \citep{kelly2015power,
  mcmurdie2014waste, benjamini1995controlling, love2014moderated}.

The purpose of this note is to describe recent efforts to bridge this gap, based
on the ``knockoffs'' procedure of \citep{barber2015controlling}, and to explore
the applicability (and remaining limitations) of recently proposed methods in
the microbiome data analysis context. To provide some context,
\citep{barber2015controlling} proposes a procedure to link two ideas that were
both introduced in the mid-1990s -- the FDR-controlling Benjamini-Hochberg
procedure and the sparsity-inducing lasso model \citep{benjamini1995controlling,
  tibshirani1996regression}. More precisely, the knockoffs procedure controls
the FDR of nonzero coefficients estimated by the lasso in a gaussian linear
model. Recently, variants of the knockoffs have been proposed that can be
applied in different settings or to provide different interpretations
\citep{janson2016familywise, candes2016panning, katsevich2017multilayer,
  sesia2017gene, fan2017rank}.

\section{Background}
\label{sec:background}

Before proceeding to microbiome-specific applications, we review the standard
setup and results shared across the knockoffs literature.

Standard knockoffs
- setup notation and definitions
- define procedure
- state theorems for FDR control

Model-free knockoffs
- state describe changes in setup
- define changes in procedure (SCIP and Gaussian example)
- state associated theorem

\section{Gaussian model for transformed data}
\label{sec:mf_gaussian_model}

\subsection{Graphical lasso}
\label{subsec:graphical_lasso}


\subsection{High-dimensional factor analysis}
\label{subsec:factor_analysis}

\section{LDA count model}
\label{sec:lda_count_model}

Suppose $X \sim LDA\left(K, \alpha\right)$ is an $n \times p$ matrix of counts,
by which we mean that the $n$ rows of $X$ are drawn according to the LDA data
generating mechanism with $K$ topics and $\theta_{i} \sim
\Dir\left(\alpha\right)$. Denote the columns of $X$ by $x_{1}, \dots, x_{p}$.

To develop model-free knockoffs $\tilde{x}_{1}, \dots, \tilde{x}_{p}$ for a
single row, we can use SCIP, sequentially sampling $\tilde{x}_{j} \sim
\mathcal{L}\left(x_{j} \vert x_{-j}, \tilde{x}_{1:j - 1}\right)$ for $j = 1,
\dots, p$. For the first knockoff, we can sample
\begin{align}
  \label{eq:first_lda_knockoff}
  \tilde{x}_{1} \sim p\left(x_{1} \vert x_{2:p}\right) &= \int p\left(x_{1} \vert \tilde{\theta}\right)p\left(\tilde{\theta} \vert x_{2:p}\right) d\tilde{\theta}
\end{align}

We can use a LDA mean-field approximation to sample from $p\left(\tilde{\theta}
\vert x_{2:p}\right)$,
\begin{align*}
  \tilde{\theta} &\sim \Dir\left(\left(\alpha_{k} + \sum_{v = 2}^{p} x_{iv} \tilde{c}_{ivk}\right)_{k= 1}^{K}\right),
\end{align*}
where $\tilde{c}_{ivk}$ are variational parameters interpreted as the count
breakdown of a single species abundance across topics. Following equation
\ref{eq:first_lda_knockoff}, we can then sample $x_{iv} \sim \Poi\left(\sum_{k}
\theta_{ik} \bar{\beta}_{kv}\right)$, where $\bar{\beta}_{k}$ is the
normalized version of $\beta_{k}$ after removing the first word.

For subsequent knockoffs, we have to make further approximations. For example,
suppose we want to sample from $\mathcal{L}\left(x_{2} \vert x_{1}, x_{3:p},
\tilde{x}_{1}\right)$. This is difficult because we have lost information on
both the true $\theta$ and knockoff $\tilde{\theta}$. One approach is to sample
instead from $\mathcal{L}\left(x_{2} \vert x_{1}, x_{3:p}\right)$ using the same
strategy as above. Alternatively, we could consider sampling 
\begin{align*}
 \tilde{\theta}_{i} &\sim \Dir\left(\left(\alpha_{k} + \sum_{v \neq 2} \tilde{c}_{ivk} x_{iv} + \tilde{x}_{i1}\tilde{c}_{i1k}\right)_{k = 1}^{K}\right) 
\end{align*}
which also takes the topic information of the first knockoff into consideration.
Note that this requires refitting (or at least updating) the LDA model for each
new knockoff.

\bibliographystyle{plainnat}
\bibliography{refs.bib}

\end{document}
